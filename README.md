# Topic-Specific Chatbot with Retrieval-Augmented Generation (RAG)

This project implements a RAG-based chatbot designed to handle topic-specific queries while maintaining conversation context. It leverages advanced AI technologies for embeddings, prompt engineering, and query processing to optimize response accuracy and relevance.

## Technologies Used

### 1. Language Model
- **LLM Used**: **Biomistral 7B**
  - Biomistral 7B was chosen for its efficient performance on domain-specific tasks, particularly in healthcare and technical domains. It provides a fine balance of speed and accuracy, making it suitable for maintaining conversation context while delivering nuanced responses.
  
### 2. Embeddings
- **Model**: **NeuML/pubmedbert-base-embeddings**
  - This model was selected due to its focus on biomedical and technical domains, aligning well with chatbot tasks such as handling healthcare and cybersecurity queries. The embeddings generated by PubMedBERT improve semantic understanding in these areas, supporting accurate document retrieval.

### 3. Vector Database
- **Database**: **Qdrant**
  - Qdrant is utilized for storing vectorized text chunks and for efficiently retrieving relevant information based on user queries. Its support for scalable similarity search optimizes the retrieval process, enabling fast and accurate responses. Qdrantâ€™s open-source, high-performance framework makes it a natural choice for handling the vectorized data in RAG systems.

### 4. Retrieval-Augmented Generation (RAG)
- RAG combines the power of a vector database with an LLM to enhance the chatbot's response capabilities. By embedding data and retrieving relevant information, RAG enables the chatbot to provide more precise, contextually relevant answers, especially when answering domain-specific queries.

### 5. Advanced Prompt Engineering
- Advanced prompt engineering is employed to improve response quality and consistency. This includes:
  - **Prompt Templates**: Domain-specific prompt templates for query types such as summarization and Q&A.
  - **Few-Shot Learning**: Adding 2-3 examples per template to ensure consistent output.
  - **Techniques**: Experimenting with strategies like chain-of-thought and self-consistency to guide the LLM in generating accurate responses.
  
### 6. Query Processing with AI
- **TextBlob**: Used for query preprocessing, including:
  - **Spell Correction**: Automatically corrects typos or misspelled words in user queries.
  - **Query Classification**: Differentiates between "summary" and "general" queries based on keywords to improve the response focus.

## Implementation Instructions

Follow these steps to set up and run the chatbot locally:

### Prerequisites
- **Python 3.7 or higher**
- **Git** (for cloning the repository)
- **Docker** (optional, for running Qdrant in a container)
- **Virtual Environment** (recommended)

### Step 1: Clone the Repository
Clone this repository to your local machine:

git clone https://github.com/NamanVSrivastav/RAG-Chatbot
cd RAG-Chatbot

### Step 2: Set Up a Virtual Environment
It's a good practice to use a virtual environment to manage dependencies. Create and activate one as follows:
Create a virtual environment
python -m venv venv

Activate the virtual environment
On Windows
venv\Scripts\activate
On macOS/Linux
source venv/bin/activate

### Step 3: Install Dependencies
Install the required packages using pip:
pip install -r requirements.txt

### Step 4: Set Up Qdrant Vector Database
You can run Qdrant using Docker for ease of setup. If you have Docker installed, use the following command:
docker run -p 6333:6333 qdrant/qdrant

### Step 5: Load Data into Vector Database
Ensure you have your data (PDF documents) in the data/ directory. Then, run the ingest.py script to load documents and create the vector database:
python ingest.py

### Step 6: Run the Application
Start the Flask application (or your chosen framework):
python app.py

### Step 7: Access the Chatbot
Open your web browser and go to http://localhost: (or the port you specified) to interact with the chatbot.

### Step 8: Test the Functionality
Test the chatbot by inputting various queries related to your chosen topic. Monitor the console for any logs or error messages.

### Step 9: Stop Qdrant
If you're running Qdrant in a Docker container, you can stop it using:





